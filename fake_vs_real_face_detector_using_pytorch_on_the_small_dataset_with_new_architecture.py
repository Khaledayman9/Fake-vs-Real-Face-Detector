# -*- coding: utf-8 -*-
"""Fake vs Real Face Detector using pytorch on the small dataset with new architecture.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PRCXLmWKBt5ZMMe-wzwCSEEZtDocfQFS
"""

!pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
# ! kaggle datasets list

!kaggle datasets download -d hamzaboulahia/hardfakevsrealfaces

!unzip hardfakevsrealfaces.zip
import zipfile
import os
import shutil
# Extract the contents of the zip file
zip_path = 'hardfakevsrealfaces.zip'
extract_path = 'hardfakevsrealfaces'
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Specify the paths to the extracted data
csv_file = os.path.join(extract_path, 'data.csv')
root_dir = extract_path

import shutil
shutil.rmtree("/content/fake")
shutil.rmtree("/content/real")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, TensorDataset
from torchvision.transforms import ToTensor, Resize
import torchvision.models as models
from PIL import Image
from sklearn.model_selection import train_test_split
import random
from sklearn.preprocessing import StandardScaler
import os
import glob
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score, roc_curve, f1_score
import torchvision.transforms as transforms

# target labels
data=pd.read_csv("/content/hardfakevsrealfaces/data.csv")
data.head()

height, width = 128, 128
X = torch.empty((data.shape[0], 3, height, width))

transform_resize = Resize((height, width))
transform_tensor = ToTensor()

for i in range(data.shape[0]):
    img_path = "/content/hardfakevsrealfaces/{}/{}.jpg".format(data.loc[i, 'label'], data.loc[i, 'images_id'])
    image = Image.open(img_path).convert("RGB")
    resized_image = transform_resize(image)
    tensor_image = transform_tensor(resized_image)
    X[i] = tensor_image

X.shape

def change_labels(x):
    return label_dict[x]

labels = data.label.unique()
label_dict = {labels[i]: i for i in range(labels.size)}

y = data.label.apply(change_labels).values
y = torch.tensor(y)
y_onehot = torch.zeros(y.size(0), labels.size)
y_onehot.scatter_(1, y.view(-1, 1), 1)

y_onehot = y_onehot.type(torch.IntTensor)
y_onehot[:5]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=8)

# Convert numpy arrays to PyTorch tensors
X_train = torch.tensor(X_train).float()
X_test = torch.tensor(X_test).float()
y_train = torch.tensor(y_train).float()
y_test = torch.tensor(y_test).float()

print(X_train)
print(X_train.shape)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)
        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 14 * 14, 64)
        self.dropout = nn.Dropout(0.45)
        self.fc2 = nn.Linear(64, 2)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.pool(nn.functional.relu(self.conv1(x)))
        x = self.pool(nn.functional.relu(self.conv2(x)))
        x = x.view(-1, 32 * 14 * 14)
        x = nn.functional.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.softmax(self.fc2(x))
        return x

model = Net()

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters())

# Create PyTorch datasets and dataloaders
train_dataset = TensorDataset(X_train, torch.argmax(y_train, dim=1))
test_dataset = TensorDataset(X_test, torch.argmax(y_test, dim=1))
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# # Training process
# epochs = 8
# for epoch in range(epochs):
#     running_loss = 0.0
#     for images, labels in train_dataloader:
#         optimizer.zero_grad()
#         outputs = model(images)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()
#         running_loss += loss.item()
#     print(f"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_dataloader)}")

# Training process
epochs = 8
for epoch in range(epochs):
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_dataloader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        # Calculate accuracy
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_dataloader)}, Accuracy: {accuracy}%")

# Evaluate the model
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_dataloader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy}%")

model.eval()
predictions = []
true_labels = []

with torch.no_grad():
    for inputs, labels in test_dataloader:
        outputs = model(inputs)
        probabilities = F.softmax(outputs, dim=1)
        _, predicted = torch.max(probabilities, 1)

        predictions.extend(probabilities[:, 1].tolist())
        true_labels.extend(labels.tolist())

auc_roc = roc_auc_score(true_labels, predictions)
print(f"AUC-ROC: {auc_roc:.4f}")

fpr, tpr, thresholds = roc_curve(true_labels, predictions)

plt.figure()
plt.plot(fpr, tpr, label='ROC curve')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

binary_predictions = [1 if p >= 0.5 else 0 for p in predictions]
f1 = f1_score(true_labels, binary_predictions)
print(f"F1 Score: {f1:.4f}")